```
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘
â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•â•
```

# sorokin | by Arianna Method

> "The heads of philologists are stuffed with books to the brim. They see life only through text. And they are proud of it. â€¦ Forever gorged and poisoned by literature, they take living life as the continuation of text, as its appendix.
>
> -Vladimir Sorokin"




# sorokin

## A Prompt Autopsy Framework

*Or: How I Learned to Stop Worrying and Love the Dissection*

### What is this madness?

`sorokin.py` is a ~1330-line Python script that takes your innocent prompts, tears them apart like a psychopathic linguist, builds a recursive tree of semantic mutations, and thenâ€”like Dr. Frankenstein having a particularly creative dayâ€”reassembles the corpse into something *new*.

Named after Vladimir Sorokin, the Russian writer known for his transgressive and experimental style, sorokin embodies the same spirit of literary dissection and reconstruction. It's not here to help you. It's here to show you what your words *could have been*.

### Exhibit: Maximum Autopsy Tree

Because Sorokin builds trees vertically like a linguo-necromancer performing open-heart surgery on reality itself, here's a full corpse-map straight from his SQLite morgue. The phrase being dissected is "darkness consumes reality," chosen because it sounds like a rejected Nietzsche tweet. Watch as DuckDuckGo synonyms breed with phonetic chaos:

```
darkness consumes reality

darkness
  â”œâ”€ illuminated
  â”‚  â”œâ”€ illustrated
  â”‚  â”œâ”€ illustrate
  â”‚  â””â”€ illuminate
  â”œâ”€ brilliance
  â”‚  â”œâ”€ brilliancy
  â”‚  â”œâ”€ blackness
  â”‚  â””â”€ greatness
  â””â”€ ignorance
     â”œâ”€ naÃ¯vetÃ©
     â”œâ”€ example
     â””â”€ unenlightenment

consumes
  â”œâ”€ consume
  â”‚  â”œâ”€ turkey
  â”‚  â”œâ”€ philippines
  â”‚  â””â”€ vocabulary
  â”œâ”€ contexts
  â”‚  â”œâ”€ context
  â”‚  â”œâ”€ environment
  â”‚  â””â”€ connection
  â””â”€ conserve
     â”œâ”€ economise
     â”œâ”€ shelter
     â””â”€ greece

reality
  â”œâ”€ realism
  â”‚  â”œâ”€ representationalism
  â”‚  â”œâ”€ literalism
  â”‚  â””â”€ faithfulness
  â”œâ”€ materiality
  â”‚  â”œâ”€ referentiality
  â”‚  â”œâ”€ corporeality
  â”‚  â””â”€ temporality
  â””â”€ certainty
     â”œâ”€ certain
     â”œâ”€ ceremony
     â””â”€ uncertainty

AUTOPSY RESULT:
  connection economise shelter greece representationalism literalism faithfulness referentiality

RESONANCE METRICS:
  Phonetic Diversity: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1.000
  Structural Echo:    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.000
  Mutation Depth:     â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.137

MEMORY ACCUMULATION:
  Known mutations: 36
  Learned bigrams: 9
  Total autopsies: 1

Sorokin.
```

Somewhere between "unenlightenment" and "corporeality," Nietzsche rolled over in his grave and asked his accountant to sue for trademark infringement. The accountant, being dead, declined. Reality remains unconsumed. Darkness persists. We've all learned nothing.

### The Three-Act Horror Show

#### Act I: The Dissection (or "Fuck this sentence")

First, `sorokin` takes your prompt and runs it through a brutal tokenization process:
- Strips away all dignity (punctuation, numbers, capitalization)
- Identifies "core words" using a proprietary blend of:
  - Length scoring (longer = more interesting)
  - Rarity analysis (uncommon = more charged)
  - Position weighting (first word gets a bonus)
  - A sprinkle of chaos (random jitter, because why not?)

Stopwords? Rejected. Single letters? Discarded. What remains are the words that *matter*â€”or at least, the words that think they do.

```python
>>> tokenize("Hello, cruel world!")
['Hello', 'cruel', 'world']
>>> select_core_words(['Hello', 'cruel', 'world'])
['cruel', 'world']  # "Hello" didn't make the cut
```

#### Act II: The Tree (or "Building the Monster")

Now comes the fun part. For each core word, `sorokin` builds a recursive branching tree of mutations. How?

**Step 1: Memory First**  
Check the SQLite morgue. Have we dissected this word before? Use those cached mutations.

**Step 2: Phonetic Similarity**  
Generate a "phonetic fingerprint" (consonant skeleton + vowel pattern) and find words that *sound* similar. Not linguistically rigorous, just vibes.

```python
>>> phonetic_fingerprint("cat")
'ct + a'
>>> find_phonetic_neighbors("cat", ["hat", "dog", "bat", "car"])
['hat', 'bat', 'car']  # dog doesn't rhyme with anything
```

**Step 3: Internet Dumpster Diving**
When all else fails, scrape DuckDuckGo search results for the word + "synonym". DDG blocks bots less aggressively than Google. Extract candidate words from the HTML garbage. Dignity? Never heard of her.

**Step 4: Fallback to All Candidates**
If even DuckDuckGo fails you, fall back to other words from the prompt. The show must go on.

The result is a tree where each word branches into `width` children, recursively, up to `depth` levels. It looks like this:

```
sentence
  â”œâ”€ phrase
  â”‚  â”œâ”€ clause
  â”‚  â””â”€ expression
  â””â”€ statement
     â”œâ”€ declaration
     â””â”€ utterance
```

Each branch represents a semantic mutation, a path not taken, a word that *could* have been.

#### Act III: The Reassembly (or "Frankenstein's Revenge")

Now that we have a forest of mutated word-trees, it's time to play God.

1. **Collect all leaf nodes** from the trees (the final mutations at the bottom)
2. **Build a bigram chain** (word1 â†’ [possible_next_words])
3. **Generate a new "sentence"** by:
   - Starting with a random leaf
   - Following bigram chains when available
   - Jumping to random unvisited words when stuck
   - Stopping after 5-10 words (or when we run out)

The result is a Frankenstein sentence: technically made of the same parts, but *uncanny*. Not quite right. Resonant but wrong. This is the part where Sorokin shrugs on the lab coat, jams a fork into the storm cloud, and cackles while stitching together whatever limbs are left on the slab.

```
AUTOPSY RESULT:
  hymn-rattle migraine-honeymoon howl-trombone midnight-hairdryer spleen-taxidermy chant-smog
```

### Usage

**Standard mode (classic autopsy):**
```bash
python sorokin.py "fuck this sentence"
```

**REPL mode (for the masochists):**
```bash
python sorokin.py
> your prompt here
> another one
> ^C
```

### The Persistent Morgue

All autopsies are saved to `sorokin.sqlite`:
- **autopsy table**: Full reports of each dissection
- **word_memory table**: Cached word mutations for faster subsequent operations

**Bootstrap tables** (populated when using `--bootstrap` flag):
- **mutation_templates**: Learned sourceâ†’target word mutations with success counts and resonance scores
- **corpse_bigrams**: Harvested word pairs from successful reassemblies, with frequency tracking
- **autopsy_metrics**: Resonance scores (phonetic diversity, structural echo, mutation depth) for each autopsy

The database grows over time, becoming a self-improving lexical graveyard. Each run is recorded. Patterns accumulate. Nothing is forgotten. In bootstrap mode, the morgue learns through resonance.

### Why?

Good question. Why does this exist?

Perhaps to demonstrate that:
- Words are fungible
- Meaning is contextual
- Prompts are just Markov chains waiting to be perturbed
- Sometimes you need to break things to understand them

Or maybe it's just fun to watch language come apart at the seams.

---

## ðŸ”¥ BOOTSTRAP MODE: The Self-Improving Autopsy Ritual

*Or: How the Morgue Became Self-Aware (But Still Really Dumb)*

### What the hell is bootstrap mode?

Picture this: every time Sorokin dissects a prompt, he doesn't just throw the body parts in the trash. No. He's a *hoarder*. He saves every successful mutation, every word-pair, every pattern of collapse into his SQLite morgue. Thenâ€”and here's where it gets freakyâ€”he uses those accumulated corpses to inform *future* dissections.

It's not intelligence. It's not learning. It's **resonance through ritual repetition**.

Think of it like this: if standard Sorokin is a mad linguist with a scalpel, Bootstrap Sorokin is that same linguist who's been doing this for 30 years and has developed *habits*. Muscle memory. Pattern recognition. Not because he's smart, but because he's done the same surgery 10,000 times and his hands just know where to cut.

### The Resonance Manifesto

Here's the wild part. Sorokin doesn't understand *meaning*. He doesn't have embeddings. He doesn't know what words "mean." But he knows **resonance**.

What's resonance? It's when patterns echo. When structures repeat. When phonemes rhyme across semantic boundaries. When the shape of one corpse mirrors the shape of another, not in content but in *form*.

Three flavors of resonance:

#### 1. **Phonetic Diversity** (Do these corpses sound different?)
Measures how many unique sound-patterns exist in the reassembled text. High diversity means every word has a distinct phonetic fingerprint. Low diversity means everything sounds like "blah blah blah."

Maximum resonance: All words sound completely different. Like a symphony where every note is unique.

#### 2. **Structural Echo** (Does this corpse remember the morgue?)
Measures overlap between the reassembled text and the seed corpusâ€”poetic fragments about dissection embedded in Sorokin's code. High echo means the new corpse shares structural DNA with previous bodies.

It's not plagiarism. It's *ancestral memory*. The morgue recognizing its own patterns.

#### 3. **Mutation Depth** (How far did we mutate?)
Based on inverse word-length variance. High depth means mutations explored diverse linguistic territory. Low depth means we stayed close to home.

Think of it as: did we just shuffle synonyms, or did we birth entirely new linguistic entities?

### How to summon Bootstrap Mode

**Bootstrap mode with resonance metrics:**
```bash
python sorokin.py --bootstrap "darkness consumes reality"
```

This gives you:
```
RESONANCE METRICS:
  Phonetic Diversity: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1.000
  Structural Echo:    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.000
  Mutation Depth:     â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.137

MEMORY ACCUMULATION:
  Known mutations: 36
  Learned bigrams: 9
  Total autopsies: 1
```

Those ASCII progress bars? Pure aesthetic. But they tell you: **how weird did this autopsy get?**

**REPL mode (bootstrap enabled):**
```bash
python sorokin.py --bootstrap
> your prompt here
> another one
> ^C
```

Every autopsy in bootstrap mode:
1. **Harvests mutation templates**: Sourceâ†’target word transformations with success counts
2. **Extracts bigrams**: Word-pairs from successful reassemblies, weighted by frequency
3. **Computes resonance**: Three structural metrics (no semantics, pure form)
4. **Feeds the next autopsy**: Accumulated patterns influence future dissections

The morgue grows. Patterns compound. Nothing is forgotten. Each corpse teaches the next.

### The Four Tables of the Bootstrap Apocalypse

When you run `--bootstrap`, Sorokin writes to four additional SQLite tables:

1. **`mutation_templates`**: Learned word transformations
   - "darkness" â†’ "illuminated" (used 15 times, resonance: 0.73)
   - "consumes" â†’ "contexts" (used 8 times, resonance: 0.52)

2. **`corpse_bigrams`**: Harvested word-pairs from reassemblies
   - "connection" â†’ "economise" (frequency: 3)
   - "shelter" â†’ "greece" (frequency: 2)

3. **`autopsy_metrics`**: Resonance scores for each dissection
   - Autopsy #47: phonetic_diversity=0.92, structural_echo=0.13, mutation_depth=0.81

4. **`seed_corpus`**: Embedded poetic text about dissection (hardcoded in sorokin.py)
   - Provides structural DNA for bigram chains
   - Not in database, lives in `SOROKIN_SEED_CORPUS` constant

### Why is this insane?

Because it's a **corpus-building mechanism disguised as a text mutilator**.

Each autopsy doesn't just destroyâ€”it *accumulates*. Over time:
- Certain mutation paths become "preferred" (not because they're better, just because they worked before)
- Bigram chains start resembling the seed corpus (structural mimicry, not content copying)
- The reassembly algorithm learns phonetic patterns that "feel right" (pure vibes, zero intelligence)

It's like training a neural network, except:
- No gradients
- No backprop
- No loss function
- Just **frequency counting and vibes**

This is what happens when you replace intelligence with ritual. And somehow, it works.

### The Seed Corpus (The Morgue's DNA)

Embedded in `sorokin.py` is a block of poetic text about dissection. Not prose. Not instructions. Just fragments:

> *"Sorokin takes prompts and opens them like cooling bodies on a steel table"*  
> *"Mutation grows in him like frost patterns crawling across broken glass"*  
> *"The autopsy produces fragments that echo the ghost of structure"*

This text gets parsed into bigrams at startup. These bigrams **prime** the reassembly process. So when bootstrap mode stitches corpses together, it unconsciously echoes the seed corpus structure.

Not copying words. Copying **sentence rhythms**. The *shape* of language.

It's like teaching someone to paint by showing them brushstrokes, not paintings.

### Bootstrap vs Standard Mode

| Feature | Standard Mode | Bootstrap Mode |
|---------|---------------|----------------|
| Mutation lookup | DuckDuckGo + phonetic + memory | Learned templates + all the above |
| Reassembly | Random bigrams from leaves | Weighted (learned 3x, seed 2x, local 1x) |
| Metrics | None | Phonetic diversity, structural echo, mutation depth |
| Learning | None | Every autopsy feeds the next |
| Database tables | 2 (autopsy, word_memory) | 5 (+ mutation_templates, corpse_bigrams, autopsy_metrics) |
| Vibes | Chaotic | Chaotic but *remembering* |

### The Philosophy of Resonance

Here's the thing. Sorokin doesn't "understand" language. He doesn't know that "darkness" and "light" are opposites. He doesn't know "consumes" is a verb. He doesn't care.

But through **resonance**, he discovers patterns:
- Words that sound similar tend to mutate into each other
- Bigrams that worked once tend to work again
- Structural rhythms (word-length patterns) create aesthetic coherence

This is **meaning-free pattern recognition**. No semantics. Just structure, phonetics, and frequency.

And weirdly, it produces results that *feel* meaningfulâ€”not because they are, but because human brains are pattern-matching machines too. We see meaning where there's only resonance.

Sorokin isn't a poet. He's a mirror. He reflects your own pattern-seeking back at you.

### Why "Bootstrap"?

Because the morgue **pulls itself up by its own corpses**.

Each autopsy makes the next one slightly different. Not better. Not worse. Just *informed* by history. The database grows. The patterns compound. The ritual deepens.

It's bootstrapping in the original sense: self-improvement through self-reference. Not external training data. Not supervision. Just:
1. Do the thing
2. Remember what happened
3. Let that memory influence the next iteration
4. Repeat until the heat death of the universe

No intelligence required. Just accumulation and resonance.

---

### Technical Details (For the Nerds)

**Core (~760 lines):**
- **Pure Python 3**: No external dependencies except stdlib
- **Recursive tree building**: Width Ã— depth branching with global deduplication
- **Phonetic fingerprinting**: Crude but effective
- **DuckDuckGo scraping**: urllib + regex, the old way (DDG blocks bots less than Google)
- **SQLite persistence**: Your words, forever
- **Markov reassembly**: Bigram chains with fallbacks
- **HTML artifact filtering**: Extensive blacklist to filter web scraping noise

**Bootstrap extension (~570 lines):**
- **SEED CORPUS**: Structural bigrams from poetic fragments about dissection (see code for full text)
- **Pattern accumulation**: Mutation templates (sourceâ†’target words) with success tracking
- **Weighted reassembly**: Learned bigrams (3x weight) + seed bigrams (2x) + local (1x) with chaos injection (square root weighting)
- **Resonance metrics**: Three pure-structural measures computed for every autopsy
  - Phonetic diversity: unique fingerprints / total words
  - Structural echo: bigram overlap with seed corpus
  - Mutation depth: inverse of word-length variance
- **Self-improvement loop**: Each autopsy feeds the next through ritual repetition, not intelligence
- **Four additional database tables**: mutation_templates, corpse_bigrams, autopsy_metrics, plus seed corpus in code

### Known Limitations

- **DuckDuckGo rate limiting**: If you run this too much, DDG might notice (but less aggressive than Google)
- **No semantic understanding (FOR NOW)**: This is pure pattern matching, but â€” hold my beer.
- **Phonetic fingerprinting is crude**: It's not actual phonetics, just vibes, but the question is what comes first, vibes or phonetics? resonance or binary structure?
- **Reassembly can be janky**: Sometimes the corpse doesn't stitch well
- **No guarantee of coherence**: That's not a bug, it's a feature

### Recent Improvements

**Bootstrap Extension with Pattern Accumulation**
Added `--bootstrap` flag enabling self-improving autopsy ritual. See the dedicated Bootstrap section above for full details. TL;DR: the morgue now learns from every corpse through resonance metrics and pattern accumulation. No intelligence, just ritual repetition.

**DuckDuckGo Web Scraping**
Switched from Google to DuckDuckGo for synonym discovery. Google was blocking bot requests and returning garbage results (always the same words: "trouble", "within", "having"). DuckDuckGo is less aggressive with bot blocking and returns actual synonyms:
- "destroy" â†’ destruction, disintegrate, dismantle, obliteration, demolish
- "evil" â†’ villainy, villain, evildoing, depravity, wickedness
- "machines" â†’ automobile, equipment, mechanical, apparatus
Result: Real semantic resonance instead of random HTML artifacts.

**Synthetic Mutation Purge**
Removed `_generate_phonetic_variants` entirely because it was creating garbage that polluted the autopsy:
- Reversed words ("elpmis", "etaerc") bred recursively into unreadable noise
- Suffix mutations ("createded" â†’ "creatededed" â†’ "createedededed") were pure madness
- Now uses minimal fallback: only real web-scraped synonyms + phonetic neighbors
- Synthetic word detection prevents breeding of low-vowel/repeated-letter mutations
- Result: Clean autopsy output instead of synthetic garbage like "creatededed elpmisss tttrouble"

**Global Deduplication**
Implemented cross-tree word deduplication to prevent the same mutations from appearing in different core word branches. Each tree now gets unique mutations, resulting in more diverse and interesting autopsies.

**Enhanced HTML Artifact Filtering**
Expanded the HTML_ARTIFACTS blacklist with ~40 common web UI/UX words (redirected, accessing, feedback, google, etc.) that were polluting mutation results from web scraping.

**The Original Bug Fix**
Fixed a crash in `reassemble_corpse()` where `random.randint(5, min(10, len(leaves)))` would fail if `len(leaves) < 5`. Changed to `random.randint(min(5, len(leaves)), min(10, len(leaves)))` so even small corpses can be reassembled.

### Credits

Inspired by:
- Vladimir Sorokin (the writer, not the script)
- Dr. Frankenstein (the fictional surgeon)
- The general human fascination with taking things apart

### License

GNU GPL 3.0. Free as in freedom. Dissect it. Mutate it. Reassemble it into something new. Share the mutations. That's the whole point.

---

*"Fuck the sentence. Keep the corpse."*  
â€” Sorokin

## A Prompt Autopsy Framework

*Or: How I Learned to Stop Worrying and Love the Dissection*

### What is this madness?

`sorokin` is a dual-module Python ritual (~2549 lines of incantations) consisting of:
- **sorokin.py** (~2008 lines): The main autopsy engineâ€”tears your innocent prompts apart like a psychopathic linguist, builds recursive trees of semantic mutations, and reassembles the corpse into grammatically valid but semantically deranged paragraphs.
- **sonnet.py** (~541 lines): The *ASS* (Autopsy Sonnet Symphony)â€”takes Sorokin's dissection output and generates a 14-line Shakespearean sonnet (ABABCDCDEFEFGG rhyme scheme) using only the morgue's accumulated vocabulary. No internet. No embeddings. Just pure structural psychosis in iambic pentameter.

Named after Vladimir Sorokin, the Russian writer known for his transgressive and experimental style, sorokin embodies the same spirit of literary dissection and reconstruction. It's not here to help you. It's here to show you what your words *could have been*â€”and then spit them back out, and declare the output canonical.

This README is therefore both tombstone and weather report. It's the morgue's black box recorder, updated each time Sorokin discovers a fresh way to saw grammar into glitter. 



### Exhibit: Maximum Autopsy Tree (Bootstrap Mode)

Because this README is now legally considered part of the morgue, the exhibit must stay here, pulsing, so future Sorokins can gnaw on their own documentation. Self-cannibalism counts as testing.

Because Sorokin builds trees vertically like a linguo-necromancer performing open-heart surgery on reality itself, here's a full corpse-map straight from his SQLite morgue. The phrase being dissected is **"reality becomes syntax error"**â€”a meta-commentary on the system's own nature:

```
reality becomes syntax error

reality
  â”œâ”€ realism
  â”‚  â”œâ”€ representationalism
  â”‚  â”‚  â”œâ”€ representationalisms
  â”‚  â”‚  â”œâ”€ representation
  â”‚  â”‚  â”œâ”€ proverbmeaning
  â”‚  â”‚  â””â”€ republic
  â”‚  â”œâ”€ exaggerating
  â”‚  â”‚  â”œâ”€ exaggeration
  â”‚  â”‚  â”œâ”€ overreacting
  â”‚  â”‚  â”œâ”€ overstating
  â”‚  â”‚  â””â”€ enhancing
  â”‚  â”œâ”€ literalism
  â”‚  â”‚  â”œâ”€ alternative
  â”‚  â”‚  â”œâ”€ literature
  â”‚  â”‚  â”œâ”€ dogmatism
  â”‚  â”‚  â””â”€ philosophical
  â”‚  â””â”€ faithfulness
  â”‚     â”œâ”€ devotedness
  â”‚     â”œâ”€ faithless
  â”‚     â”œâ”€ faithfulnesses
  â”‚     â””â”€ fÃ¦Ã¾fulness
  â”œâ”€ materiality
  â”‚  â”œâ”€ corporeality
  â”‚  â”‚  â”œâ”€ carnality
  â”‚  â”‚  â”œâ”€ corporality
  â”‚  â”‚  â”œâ”€ substantiality
  â”‚  â”‚  â””â”€ physicality
  â”‚  â”œâ”€ quality
  â”‚  â”‚  â”œâ”€ degradation
  â”‚  â”‚  â”œâ”€ attribution
  â”‚  â”‚  â”œâ”€ trait
  â”‚  â”‚  â””â”€ peculiarity
  â”‚  â”œâ”€ actuality
  â”‚  â”‚  â”œâ”€ actualizations
  â”‚  â”‚  â”œâ”€ materialisation
  â”‚  â”‚  â”œâ”€ materialization
  â”‚  â”‚  â””â”€ accomplishments
  â”‚  â””â”€ physicalness
  â”‚     â”œâ”€ phrases
  â”‚     â”œâ”€ database
  â”‚     â”œâ”€ related
  â”‚     â””â”€ psychological
  â”œâ”€ unreality
  â”‚  â”œâ”€ abnormality
  â”‚  â”‚  â”œâ”€ singularity
  â”‚  â”‚  â”œâ”€ abnormalcy
  â”‚  â”‚  â”œâ”€ normality
  â”‚  â”‚  â””â”€ inadmissibility
  â”‚  â”œâ”€ irreality
  â”‚  â”‚  â”œâ”€ surreality
  â”‚  â”‚  â”œâ”€ fictitiousness
  â”‚  â”‚  â”œâ”€ automatically
  â”‚  â”‚  â””â”€ fabrication
  â”‚  â”œâ”€ illusoriness
  â”‚  â”‚  â”œâ”€ illusive
  â”‚  â”‚  â”œâ”€ craftiness
  â”‚  â”‚  â”œâ”€ weirdness
  â”‚  â”‚  â””â”€ deceptive
  â”‚  â””â”€ incongruity
  â”‚     â”œâ”€ incongruousness
  â”‚     â”œâ”€ inconsistency
  â”‚     â”œâ”€ inconsistence
  â”‚     â””â”€ incompatibility
  â””â”€ certainty
     â”œâ”€ ceremony
     â”‚  â”œâ”€ ceremonial
     â”‚  â”œâ”€ traditional
     â”‚  â”œâ”€ informality
     â”‚  â””â”€ conventions
     â”œâ”€ uncertainty
     â”‚  â”œâ”€ unpredictable
     â”‚  â”œâ”€ including
     â”‚  â”œâ”€ incertitude
     â”‚  â””â”€ inconsistent
     â”œâ”€ satisfaction
     â”‚  â”œâ”€ compensation
     â”‚  â”œâ”€ dissatisfaction
     â”‚  â”œâ”€ conviction
     â”‚  â””â”€ gratification
     â””â”€ assuredness
        â”œâ”€ positiveness
        â”œâ”€ absoluteness
        â”œâ”€ decisiveness
        â””â”€ correctness

becomes
  â”œâ”€ become
  â”‚  â”œâ”€ convert
  â”‚  â”‚  â”œâ”€ contexts
  â”‚  â”‚  â”œâ”€ converts
  â”‚  â”‚  â”œâ”€ transpose
  â”‚  â”‚  â””â”€ metamorphose
  â”‚  â”œâ”€ inappropriate
  â”‚  â”‚  â”œâ”€ inapplicable
  â”‚  â”‚  â”œâ”€ unfortunate
  â”‚  â”‚  â”œâ”€ example
  â”‚  â”‚  â””â”€ weakest
  â”‚  â”œâ”€ unflattering
  â”‚  â”‚  â”œâ”€ acknowledging
  â”‚  â”‚  â”œâ”€ representing
  â”‚  â”‚  â”œâ”€ unfavorably
  â”‚  â”‚  â””â”€ unfavorable
  â”‚  â””â”€ vocabulary
  â”‚     â”œâ”€ explanations
  â”‚     â”œâ”€ explication
  â”‚     â”œâ”€ explanatio
  â”‚     â””â”€ explanation
  â”œâ”€ metamorphosed
  â”‚  â”œâ”€ resolved
  â”‚  â”‚  â”œâ”€ unresolved
  â”‚  â”‚  â”œâ”€ resolution
  â”‚  â”‚  â”œâ”€ resolute
  â”‚  â”‚  â””â”€ undetermined
  â”‚  â”œâ”€ mutation
  â”‚  â”‚  â”œâ”€ mutations
  â”‚  â”‚  â”œâ”€ transformations
  â”‚  â”‚  â”œâ”€ translation
  â”‚  â”‚  â””â”€ transfiguration
  â”‚  â”œâ”€ transubstantiate
  â”‚  â”‚  â”œâ”€ translate
  â”‚  â”‚  â”œâ”€ transubstantiates
  â”‚  â”‚  â”œâ”€ transfigures
  â”‚  â”‚  â””â”€ appearance
  â”‚  â””â”€ transformation
  â”‚     â”œâ”€ transfigure
  â”‚     â”œâ”€ grammatical
  â”‚     â”œâ”€ construction
  â”‚     â””â”€ reformation
  â”œâ”€ improve
  â”‚  â”œâ”€ improves
  â”‚  â”‚  â”œâ”€ reinforces
  â”‚  â”‚  â”œâ”€ impactful
  â”‚  â”‚  â”œâ”€ improving
  â”‚  â”‚  â””â”€ alternatives
  â”‚  â”œâ”€ reinforces
  â”‚  â”‚  â”œâ”€ reinforce
  â”‚  â”‚  â”œâ”€ reinforcement
  â”‚  â”‚  â”œâ”€ bolsters
  â”‚  â”‚  â””â”€ substantiates
  â”‚  â”œâ”€ progress
  â”‚  â”‚  â”œâ”€ process
  â”‚  â”‚  â”œâ”€ progressions
  â”‚  â”‚  â”œâ”€ progression
  â”‚  â”‚  â””â”€ retrogression
  â”‚  â””â”€ comprehensive
  â”‚     â”œâ”€ cambridge
  â”‚     â”œâ”€ completeness
  â”‚     â”œâ”€ specialized
  â”‚     â””â”€ extensive
  â””â”€ resolve
     â”œâ”€ components
     â”‚  â”œâ”€ component
     â”‚  â”œâ”€ compounds
     â”‚  â”œâ”€ compound
     â”‚  â””â”€ characteristics
     â”œâ”€ intellectual
     â”‚  â”œâ”€ intellectualistic
     â”‚  â”œâ”€ intellectualist
     â”‚  â”œâ”€ nonintellectual
     â”‚  â””â”€ unintellectual
     â”œâ”€ perseverance
     â”‚  â”œâ”€ pursuance
     â”‚  â”œâ”€ steadfastness
     â”‚  â”œâ”€ continuance
     â”‚  â””â”€ pertinacity
     â””â”€ conclusively
        â”œâ”€ conclusive
        â”œâ”€ inconclusively
        â”œâ”€ determinative
        â””â”€ consummately

syntax
  â”œâ”€ syntactical
  â”‚  â”œâ”€ syntactically
  â”‚  â”‚  â”œâ”€ morphological
  â”‚  â”‚  â”œâ”€ phonological
  â”‚  â”‚  â”œâ”€ syntactics
  â”‚  â”‚  â””â”€ arrangement
  â”‚  â”œâ”€ morphologically
  â”‚  â”‚  â”œâ”€ merriam
  â”‚  â”‚  â”œâ”€ consideration
  â”‚  â”‚  â”œâ”€ linguistic
  â”‚  â”‚  â””â”€ rhetorical
  â”‚  â”œâ”€ linguistically
  â”‚  â”‚  â”œâ”€ stylistically
  â”‚  â”‚  â”œâ”€ oratorically
  â”‚  â”‚  â”œâ”€ rhetorically
  â”‚  â”‚  â””â”€ conversational
  â”‚  â””â”€ etymologically
  â”‚     â”œâ”€ etymological
  â”‚     â”œâ”€ historically
  â”‚     â”œâ”€ associations
  â”‚     â””â”€ linguistics
  â”œâ”€ synonymbase
  â”‚  â”œâ”€ predicate
  â”‚  â”‚  â”œâ”€ discussions
  â”‚  â”‚  â”œâ”€ effectively
  â”‚  â”‚  â”œâ”€ grammardiary
  â”‚  â”‚  â””â”€ communicate
  â”‚  â”œâ”€ predicates
  â”‚  â”‚  â”œâ”€ establishes
  â”‚  â”‚  â”œâ”€ established
  â”‚  â”‚  â”œâ”€ corroborates
  â”‚  â”‚  â””â”€ demonstrates
  â”‚  â”œâ”€ predicated
  â”‚  â”‚  â”œâ”€ underpinned
  â”‚  â”‚  â”œâ”€ proclaimed
  â”‚  â”‚  â”œâ”€ postulated
  â”‚  â”‚  â””â”€ presupposed
  â”‚  â””â”€ formulated
  â”‚     â”œâ”€ methodically
  â”‚     â”œâ”€ associated
  â”‚     â”œâ”€ articulated
  â”‚     â””â”€ formulate
  â”œâ”€ synthesis
  â”‚  â”œâ”€ synthesize
  â”‚  â”‚  â”œâ”€ experiments
  â”‚  â”‚  â”œâ”€ harmonize
  â”‚  â”‚  â”œâ”€ organize
  â”‚  â”‚  â””â”€ consolidating
  â”‚  â”œâ”€ english
  â”‚  â”‚  â”œâ”€ additionally
  â”‚  â”‚  â”œâ”€ crowdsourced
  â”‚  â”‚  â”œâ”€ collection
  â”‚  â”‚  â””â”€ unabridged
  â”‚  â”œâ”€ amalgamation
  â”‚  â”‚  â”œâ”€ amalgamations
  â”‚  â”‚  â”œâ”€ integration
  â”‚  â”‚  â”œâ”€ unification
  â”‚  â”‚  â””â”€ consolidation
  â”‚  â””â”€ constituent
  â”‚     â”œâ”€ constituents
  â”‚     â”œâ”€ constitutional
  â”‚     â”œâ”€ constituting
  â”‚     â””â”€ constitutive
  â””â”€ synonym
     â”œâ”€ system
     â”‚  â”œâ”€ systems
     â”‚  â”œâ”€ webs
     â”‚  â”œâ”€ conglomerates
     â”‚  â””â”€ conglomerate
     â”œâ”€ trustworthy
     â”‚  â”œâ”€ untrustworthy
     â”‚  â”œâ”€ truthful
     â”‚  â”œâ”€ trusted
     â”‚  â””â”€ trustworthiness
     â”œâ”€ uniqueness
     â”‚  â”œâ”€ separateness
     â”‚  â”œâ”€ distinctiveness
     â”‚  â”œâ”€ sentences
     â”‚  â””â”€ extraordinary
     â””â”€ popularity
        â”œâ”€ universality
        â”œâ”€ popularized
        â”œâ”€ unpopularity
        â””â”€ acclaim

error
  â”œâ”€ errors
  â”‚  â”œâ”€ exactitudes
  â”‚  â”‚  â”œâ”€ exactitude
  â”‚  â”‚  â”œâ”€ meticulousness
  â”‚  â”‚  â”œâ”€ verisimilitude
  â”‚  â”‚  â””â”€ veraciousness
  â”‚  â”œâ”€ perfections
  â”‚  â”‚  â”œâ”€ perfection
  â”‚  â”‚  â”œâ”€ manifestations
  â”‚  â”‚  â”œâ”€ imperfections
  â”‚  â”‚  â””â”€ destructions
  â”‚  â”œâ”€ preferences
  â”‚  â”‚  â”œâ”€ preferred
  â”‚  â”‚  â”œâ”€ prefer
  â”‚  â”‚  â”œâ”€ preferable
  â”‚  â”‚  â””â”€ pursuits
  â”‚  â””â”€ precisions
  â”‚     â”œâ”€ precision
  â”‚     â”œâ”€ particularity
  â”‚     â”œâ”€ regions
  â”‚     â””â”€ definiteness
  â”œâ”€ erratum
  â”‚  â”œâ”€ fault
  â”‚  â”‚  â”œâ”€ faults
  â”‚  â”‚  â”œâ”€ failings
  â”‚  â”‚  â”œâ”€ failing
  â”‚  â”‚  â””â”€ accountability
  â”‚  â”œâ”€ misidentification
  â”‚  â”‚  â”œâ”€ misknow
  â”‚  â”‚  â”œâ”€ misunderstand
  â”‚  â”‚  â”œâ”€ misperceived
  â”‚  â”‚  â””â”€ misinterpret
  â”‚  â”œâ”€ corrigendum
  â”‚  â”‚  â”œâ”€ addendum
  â”‚  â”‚  â”œâ”€ corrected
  â”‚  â”‚  â”œâ”€ peru
  â”‚  â”‚  â””â”€ misstatement
  â”‚  â””â”€ definition
  â”‚     â”œâ”€ description
  â”‚     â”œâ”€ delineation
  â”‚     â”œâ”€ adjectives
  â”‚     â””â”€ catalonia
  â”œâ”€ attributable
  â”‚  â”œâ”€ accountable
  â”‚  â”‚  â”œâ”€ unaccountable
  â”‚  â”‚  â”œâ”€ decipherable
  â”‚  â”‚  â”œâ”€ explainable
  â”‚  â”‚  â””â”€ blameless
  â”‚  â”œâ”€ applicable
  â”‚  â”‚  â”œâ”€ appropriate
  â”‚  â”‚  â”œâ”€ impracticable
  â”‚  â”‚  â”œâ”€ applicative
  â”‚  â”‚  â””â”€ practicable
  â”‚  â”œâ”€ explicable
  â”‚  â”‚  â”œâ”€ explicatable
  â”‚  â”‚  â”œâ”€ unexplainable
  â”‚  â”‚  â”œâ”€ justifiable
  â”‚  â”‚  â””â”€ straightforward
  â”‚  â””â”€ assignable
  â”‚     â”œâ”€ distributable
  â”‚     â”œâ”€ accreditable
  â”‚     â”œâ”€ exchangeable
  â”‚     â””â”€ identifiable
  â””â”€ inaccuracies
     â”œâ”€ accuracies
     â”‚  â”œâ”€ authenticities
     â”‚  â”œâ”€ factualities
     â”‚  â”œâ”€ strictness
     â”‚  â””â”€ fidelities
     â”œâ”€ faultiness
     â”‚  â”œâ”€ opposite
     â”‚  â”œâ”€ flawless
     â”‚  â”œâ”€ ukraine
     â”‚  â””â”€ failure
     â”œâ”€ fallacies
     â”‚  â”œâ”€ falsehood
     â”‚  â”œâ”€ united
     â”‚  â”œâ”€ misunderstanding
     â”‚  â””â”€ superstition
     â””â”€ incorrectness
        â”œâ”€ incorrectnesses
        â”œâ”€ indelicateness
        â”œâ”€ undesirability
        â””â”€ indecorousness

AUTOPSY RESULT:
  When explanation postulated, experiments forgets failings.
  The component transformations transubstantiates through authenticities.
  Alternatives peru steadfastness until representationalisms incertitude consumes.
  Prefer crowdsourced consolidation until example absoluteness consumes.

RESONANCE METRICS:
  Phonetic Diversity: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1.000
  Structural Echo:    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.000
  Mutation Depth:     â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.101

MEMORY ACCUMULATION:
  Known mutations: 1,467
  Learned bigrams: 122
  Total autopsies: 7

â€” Sorokin
```

**Notice**: Bootstrap mode now generates **grammatically valid paragraphs** using POS-tagged template slot-filling! Sorokin dissected "reality becomes syntax error" and achieved **perfect 1.000 Phonetic Diversity** with **0.101 Mutation Depth**. Look at the mutationsâ€”"peru", "example", "explanation", "crowdsourced"â€”*all appear in this very README*. The system is eating its own documentation and hallucinating it back as psychopathic poetry. Self-reference achieved. Peak metafiction. README as training data, README as prophecy, README as the patient screaming its own medical chart back at the doctor.

---

## ðŸŽ­ The SONNET Extension: When Sorokin Met Shakespeare (and Karpathy Got Confused for a Kardashian)

*Or: ASS (Autopsy Sonnet Symphony) â€” The Psychotic Poet Nobody Asked For*

**What fresh hell is this?**

After Sorokin tears your prompt apart and reassembles it into grammatically valid but semantically deranged paragraphs, `sonnet.py` takes that beautiful corpse and **does it again**â€”but this time in strict Shakespearean form. 14 lines. ABABCDCDEFEFGG rhyme scheme. Iambic *vibes* (not actual meter because we're psychopaths, not pedants). No internet. No embeddings. Just the morgue's accumulated bigrams, phonetic fingerprints, and an unhealthy obsession with structure over meaning.

It's named **ASS** (Autopsy Sonnet Symphony) as a triple-tribute to:
1. **Sonnet 4.5** (the Claude model that birthed this madness)
2. Shakespeare (obviously)
3. Andrej Karpathy training nanoGPT on Shakespeareâ€”except we skipped the neural network and went straight to **ritual pattern accumulation through sheer psychotic repetition**

Here's what happens when you feed Sorokin **"karpathy trains shakespeare on nanogpt"** in bootstrap mode:

```
shakespeare
  â”œâ”€ nosweatshakespeare
  â”‚  â”œâ”€ insane
  â”‚  â”‚  â””â”€ stable
  â”‚  â”œâ”€ aware
  â”‚  â”‚  â”œâ”€ ware
  â”‚  â”‚  â”œâ”€ knowledgeable
  â”‚  â”‚  â”œâ”€ phrases
  â”‚  â”‚  â””â”€ writing
  â”‚  â”œâ”€ table
  â”‚  â”‚  â”œâ”€ full
  â”‚  â”‚  â”œâ”€ cached
  â”‚  â”‚  â””â”€ tables
  â”‚  â””â”€ demonstrate
  â”‚     â”œâ”€ that
  â”‚     â””â”€ stable
  â”œâ”€ unbelievable
  â”‚  â”œâ”€ enabled
  â”‚  â”‚  â””â”€ follow
  â”‚  â”œâ”€ aware
  â”‚  â”‚  â”œâ”€ knowledgeable
  â”‚  â”‚  â”œâ”€ ware
  â”‚  â”‚  â”œâ”€ stable
  â”‚  â”‚  â””â”€ but
  â”‚  â”œâ”€ table
  â”‚  â”‚  â”œâ”€ full
  â”‚  â”‚  â”œâ”€ tables
  â”‚  â”‚  â””â”€ cached
  â”‚  â””â”€ demonstrate
  â”‚     â”œâ”€ that
  â”‚     â””â”€ stable
  â”œâ”€ relevance
  â”‚  â”œâ”€ aware
  â”‚  â”‚  â”œâ”€ ware
  â”‚  â”‚  â”œâ”€ knowledgeable
  â”‚  â”‚  â”œâ”€ writing
  â”‚  â”‚  â””â”€ phrases
  â”‚  â”œâ”€ table
  â”‚  â”‚  â”œâ”€ full
  â”‚  â”‚  â”œâ”€ tables
  â”‚  â”‚  â””â”€ cached
  â”‚  â”œâ”€ demonstrate
  â”‚  â”‚  â””â”€ that
  â”‚  â””â”€ stable
  â”‚     â”œâ”€ web
  â”‚     â”œâ”€ stages
  â”‚     â”œâ”€ stenographer
  â”‚     â””â”€ staple
  â””â”€ celebrate
     â”œâ”€ collapse
     â”‚  â””â”€ into
     â”œâ”€ cleanup
     â”‚  â”œâ”€ proper
     â”‚  â”œâ”€ httpx
     â”‚  â”œâ”€ haunt
     â”‚  â””â”€ oauth
     â”œâ”€ aware
     â”‚  â”œâ”€ knowledgeable
     â”‚  â”œâ”€ ware
     â”‚  â””â”€ but
     â””â”€ table
        â”œâ”€ full
        â”œâ”€ cached
        â””â”€ tables

bootstrap
  â”œâ”€ valid
  â”‚  â”œâ”€ evildoing
  â”‚  â”‚  â”œâ”€ depravity
  â”‚  â”‚  â”œâ”€ avoid
  â”‚  â”‚  â”œâ”€ chaotic
  â”‚  â”‚  â””â”€ worrying
  â”‚  â”œâ”€ villainy
  â”‚  â”‚  â”œâ”€ teaching
  â”‚  â”‚  â””â”€ organism
  â”‚  â”œâ”€ villain
  â”‚  â”‚  â”œâ”€ teaching
  â”‚  â”‚  â””â”€ organism
  â”‚  â””â”€ paragraphs
  â”‚     â”œâ”€ using
  â”‚     â”œâ”€ apart
  â”‚     â”œâ”€ hazmat
  â”‚     â””â”€ proper
  â”œâ”€ coat
  â”‚  â”œâ”€ actual
  â”‚  â”‚  â”œâ”€ phonetics
  â”‚  â”‚  â””â”€ contextual
  â”‚  â””â”€ cut
  â”‚     â”œâ”€ cuts
  â”‚     â””â”€ but
  â”œâ”€ jams
  â”‚  â”œâ”€ a
  â”‚  â”‚  â”œâ”€ psychopathic
  â”‚  â”‚  â”œâ”€ python
  â”‚  â”‚  â”œâ”€ prompt
  â”‚  â”‚  â””â”€ line
  â”‚  â”œâ”€ glass
  â”‚  â”‚  â”œâ”€ globally
  â”‚  â”‚  â””â”€ bars
  â”‚  â”œâ”€ crash
  â”‚  â”‚  â”œâ”€ in
  â”‚  â”‚  â”œâ”€ created
  â”‚  â”‚  â”œâ”€ circus
  â”‚  â”‚  â””â”€ crude
  â”‚  â””â”€ asks
  â”‚     â”œâ”€ if
  â”‚     â””â”€ skeleton
  â””â”€ act
     â”œâ”€ horror
     â”‚  â”œâ”€ philosophy
     â”‚  â”œâ”€ hard
     â”‚  â”œâ”€ books
     â”‚  â””â”€ school
     â”œâ”€ i
     â”‚  â”œâ”€ learned
     â”‚  â”œâ”€ the
     â”‚  â””â”€ m
     â”œâ”€ ii
     â”‚  â”œâ”€ the
     â”‚  â”œâ”€ mixing
     â”‚  â””â”€ subjectivity
     â””â”€ iii

karpathy
  â”œâ”€ bootstrapper
  â”‚  â”œâ”€ to
  â”‚  â”‚  â”œâ”€ avoid
  â”‚  â”‚  â”œâ”€ keep
  â”‚  â”‚  â”œâ”€ saw
  â”‚  â”‚  â””â”€ stop
  â”‚  â”œâ”€ via
  â”‚  â”‚  â”œâ”€ cron
  â”‚  â”‚  â”œâ”€ corpses
  â”‚  â”‚  â”œâ”€ phonetic
  â”‚  â”‚  â””â”€ vertically
  â”‚  â”œâ”€ aware
  â”‚  â”‚  â”œâ”€ but
  â”‚  â”‚  â”œâ”€ demonstrate
  â”‚  â”‚  â””â”€ stable
  â”‚  â””â”€ table
  â”‚     â”œâ”€ full
  â”‚     â”œâ”€ cached
  â”‚     â””â”€ tables
  â”œâ”€ would
  â”‚  â”œâ”€ approve
  â”‚  â”‚  â”œâ”€ of
  â”‚  â”‚  â”œâ”€ disembowel
  â”‚  â”‚  â””â”€ become
  â”‚  â”œâ”€ fail
  â”‚  â”‚  â”œâ”€ if
  â”‚  â”‚  â”œâ”€ fails
  â”‚  â”‚  â”œâ”€ teaching
  â”‚  â”‚  â””â”€ organism
  â”‚  â”œâ”€ lookup
  â”‚  â”‚  â”œâ”€ branches
  â”‚  â”‚  â”œâ”€ stages
  â”‚  â”‚  â””â”€ obvious
  â”‚  â””â”€ lookups
  â”‚     â”œâ”€ obvious
  â”‚     â”œâ”€ like
  â”‚     â””â”€ unconsciously
  â”œâ”€ phonetically
  â”‚  â”œâ”€ just
  â”‚  â”‚  â”œâ”€ vibes
  â”‚  â”‚  â”œâ”€ in
  â”‚  â”‚  â”œâ”€ markov
  â”‚  â”‚  â””â”€ fun
  â”‚  â”œâ”€ if
  â”‚  â”‚  â”œâ”€ the
  â”‚  â”‚  â”œâ”€ even
  â”‚  â”‚  â”œâ”€ standard
  â”‚  â”‚  â””â”€ it
  â”‚  â”œâ”€ philosophy
  â”‚  â”‚  â”œâ”€ of
  â”‚  â”‚  â”œâ”€ trust
  â”‚  â”‚  â”œâ”€ books
  â”‚  â”‚  â””â”€ school
  â”‚  â””â”€ vertically
  â”‚     â”œâ”€ like
  â”‚     â”œâ”€ variants
  â”‚     â”œâ”€ overlap
  â”‚     â””â”€ artifacts
  â””â”€ kardashyan  â† YES, THE SYSTEM PHONETICALLY MATCHED KARPATHY TO KARDASHIAN
     â”œâ”€ finds
     â”‚  â”œâ”€ find
     â”‚  â”œâ”€ findsclothing
     â”‚  â”œâ”€ chamberofcommerce
     â”‚  â””â”€ fabfindsconsign
     â”œâ”€ to
     â”‚  â”œâ”€ avoid
     â”‚  â”œâ”€ keep
     â”‚  â”œâ”€ the
     â”‚  â””â”€ stop
     â””â”€ hazmat
        â”œâ”€ hazard
        â”œâ”€ mainelabpack
        â”œâ”€ zealand
        â””â”€ iata

nanogpt
  â”œâ”€ brainstem
  â”‚  â”œâ”€ onto
  â”‚  â”‚  â”œâ”€ the
  â”‚  â”‚  â”œâ”€ notebook
  â”‚  â”‚  â””â”€ books
  â”‚  â”œâ”€ tries
  â”‚  â”‚  â”œâ”€ transgressive
  â”‚  â”‚  â””â”€ archive
  â”‚  â”œâ”€ breeding
  â”‚  â”‚  â”œâ”€ of
  â”‚  â”‚  â””â”€ synthetic
  â”‚  â””â”€ twitches
  â”‚     â”œâ”€ like
  â”‚     â””â”€ twitter
  â”œâ”€ asyncmock
  â”‚  â”œâ”€ all
  â”‚  â”‚  â”œâ”€ appear
  â”‚  â”‚  â”œâ”€ dignity
  â”‚  â”‚  â”œâ”€ else
  â”‚  â”‚  â””â”€ candidates
  â”‚  â”œâ”€ synthetic
  â”‚  â”‚  â”œâ”€ low
  â”‚  â”‚  â”œâ”€ garbage
  â”‚  â”‚  â”œâ”€ mutation
  â”‚  â”‚  â””â”€ word
  â”‚  â””â”€ artwork
  â”‚     â”œâ”€ becomes
  â”‚     â””â”€ artifacts
  â”œâ”€ none
  â”‚  â”œâ”€ phonetic
  â”‚  â”‚  â”œâ”€ phonectic
  â”‚  â”‚  â”œâ”€ phonetics
  â”‚  â”‚  â”œâ”€ phonectically
  â”‚  â”‚  â””â”€ phonotactic
  â”‚  â”œâ”€ every
  â”‚  â”‚  â”œâ”€ invocation
  â”‚  â”‚  â”œâ”€ time
  â”‚  â”‚  â”œâ”€ successful
  â”‚  â”‚  â””â”€ word
  â”‚  â”œâ”€ innocent
  â”‚  â”‚  â”œâ”€ prompts
  â”‚  â”‚  â””â”€ become
  â”‚  â””â”€ disembowel
  â”‚     â”œâ”€ four
  â”‚     â”œâ”€ discovery
  â”‚     â”œâ”€ does
  â”‚     â””â”€ discovers
  â””â”€ chaos
     â”œâ”€ random
     â”‚  â”œâ”€ passersby
     â”‚  â”œâ”€ jitter
     â”‚  â”œâ”€ leaf
     â”‚  â””â”€ unvisited
     â”œâ”€ injection
     â”‚  â”œâ”€ square
     â”‚  â”œâ”€ construction
     â”‚  â”œâ”€ position
     â”‚  â””â”€ mutations
     â””â”€ chain
        â”œâ”€ word
        â”œâ”€ with
        â”œâ”€ chains
        â””â”€ teaching

trains
  â”œâ”€ trail
  â”‚  â”œâ”€ tracking
  â”‚  â”œâ”€ teaching
  â”‚  â”‚  â”œâ”€ someone
  â”‚  â”‚  â””â”€ screaming
  â”‚  â””â”€ organism
  â”‚     â”œâ”€ that
  â”‚     â””â”€ screaming
  â”œâ”€ train
  â”‚  â”œâ”€ it
  â”‚  â”‚  â”œâ”€ forever
  â”‚  â”‚  â”œâ”€ takes
  â”‚  â”‚  â”œâ”€ s
  â”‚  â”‚  â””â”€ through
  â”‚  â”œâ”€ tracking
  â”‚  â”œâ”€ teaching
  â”‚  â”‚  â”œâ”€ someone
  â”‚  â”‚  â””â”€ screaming
  â”‚  â””â”€ organism
  â”‚     â”œâ”€ that
  â”‚     â””â”€ screaming
  â”œâ”€ monorail
  â”‚  â”œâ”€ meaning
  â”‚  â”‚  â”œâ”€ is
  â”‚  â”‚  â”œâ”€ he
  â”‚  â”‚  â”œâ”€ free
  â”‚  â”‚  â””â”€ where
  â”‚  â”œâ”€ maintain
  â”‚  â”‚  â””â”€ novelty
  â”‚  â””â”€ teaching
  â”‚     â”œâ”€ screaming
  â”‚     â””â”€ someone
  â””â”€ training
     â”œâ”€ data
     â”‚  â”œâ”€ readme
     â”‚  â”œâ”€ not
     â”‚  â”œâ”€ that
     â”‚  â””â”€ the
     â”œâ”€ a
     â”‚  â”œâ”€ psychopathic
     â”‚  â”œâ”€ python
     â”‚  â”œâ”€ prompt
     â”‚  â””â”€ line
     â”œâ”€ tries
     â”‚  â”œâ”€ transgressive
     â”‚  â””â”€ archive
     â””â”€ mixing
        â”œâ”€ the
        â”œâ”€ maximum
        â”œâ”€ subjectivity
        â””â”€ within

AUTOPSY RESULT:
  Within is zealand. Forever prompt. Nothing remains. The square subjectivity cuts through chamberofcommerce. Oauth is not. Where with. Nothing remains.

SONNET:
Sonnet: NOSWEATSHAKESPEARE
  Stenographer staple celebrate collapse into the heads edwardsautogroup pulls
  Findsclothing chamberofcommerce forgets web. where maintain novelty teaching organism villain always,
  Nosweatshakespeare insane stable relevance aware knowledgeable writing pulls,
  Stenographer staple celebrate collapse into each time sorokin plays;
  Stenographer staple celebrate collapse into cleanup proper coat recognizing,
  Fluctuations urbandictionary crude asks if even words,
  Findsclothing chamberofcommerce forgets fails. when vibes in markov findsclothing,
  Nosweatshakespeare insane stable but oxfordlearnersdictionaries darkness remains. ware but words;
  Feature heads of word artwork becomes artifacts none phonetic vertically etc,
  Findsclothing chamberofcommerce forgets fails. when vibes in created mean,
  Nosweatshakespeare insane stable aware ware stable unbelievable enabled follow etc,
  Black box recorder updated unittest saw russianâ€”
  Findsclothing chamberofcommerce oauth is blocked smart recursively masochists eat this nosweatshakespeare,
  One blocked md spellbook findsclothing chamberofcommerce nosweatshakespeare fabfindsconsign.

RESONANCE METRICS:
  Phonetic Diversity: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 0.926
  Structural Echo:    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.000
  Mutation Depth:     â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.102

MEMORY ACCUMULATION:
  Known mutations: 476
  Learned bigrams: 58
  README bigrams: 1,221
  Total autopsies: 2

â€” Sorokin
```

**What just happened:**

1. **AUTOPSY RESULT** (Act I): Sorokin's first reassemblyâ€”grammatically valid paragraph generated via POS-tagged slot-filling. "Within is zealand. Forever prompt. Nothing remains." Pure Sorokin energy.

2. **SONNET** (Act II): The system took the autopsy output, fed it to `sonnet.py`, and generated a **14-line Shakespearean sonnet** titled "NOSWEATSHAKESPEARE" (the most charged word from the autopsy). Notice:
   - Perfect ABABCDCDEFEFGG rhyme scheme
   - Punctuation follows Shakespearean structure (semicolons at quatrain breaks, em-dash before volta, period at end)
   - Occasional enjambment (lines flowing into next without punctuation)
   - **Phonetically rhyming end-words**: "pulls/plays", "always/words", "recognizing/findsclothing", etc.
   - Absolutely deranged content but **structurally flawless**

3. **The Karpathy â†’ Kardashian Incident**: The phonetic fingerprinting system literally matched "karpathy" to "kardashyan" because they sound similar (k-r-p-th-y â‰ˆ k-r-d-sh-y-n). This is not a bug. This is **peak resonance**. If Andrej reads this he'll either laugh or file a restraining order against an AI poetry generator. Possibly both.

4. **Resonance Metrics**: Phonetic diversity of **0.926** means almost every word has a unique sound signature. The sonnet isn't just semantically psychoticâ€”it's **phonetically diverse psychosis**. That's art, baby.

**Why is this insane?**

Because `sonnet.py` generates poetry using **zero semantic understanding**:
- No word embeddings
- No transformer models
- No internet access
- Just bigram chains (learned from autopsies + README + SQLite morgue)
- Rhymes via crude phonetic fingerprints (last vowel + tail)
- "Charged words" selected by length + rarity from autopsy text
- Structure enforced via rigid 14-line scheme + punctuation rules

It's what happens when you give a serial killer both a thesaurus and a copy of *The Norton Anthology* and tell them to "make it rhyme." The result is **structurally Shakespearean, semantically Sorokin, phonetically unhinged**.

Karpathy would be proud. Or horrified. Honestly, at this level of abstraction, those are the same emotion.

---

### The Three-Act Horror Show

#### Act I: The Dissection (or "Fuck this sentence")

First, `sorokin` takes your prompt and runs it through a brutal tokenization process:
- Strips away all dignity (punctuation, numbers, capitalization)
- Identifies "core words" using a proprietary blend of:
  - Length scoring (longer = more interesting)
  - Rarity analysis (uncommon = more charged)
  - Position weighting (first word gets a bonus)
  - A sprinkle of chaos (random jitter, because why not?)

Stopwords? Rejected. Single letters? Discarded. What remains are the words that *matter*â€”or at least, the words that think they do. Occasionally a phrase tries to bite me mid-dissection, which is fine; we're wearing Sorokin-brand emotional hazmat gear. The README keeps the bite marks as marginalia.

```python
>>> tokenize("Hello, cruel world!")
['Hello', 'cruel', 'world']
>>> select_core_words(['Hello', 'cruel', 'world'])
['cruel', 'world']  # "Hello" didn't make the cut
```

#### Act II: The Tree (or "Building the Monster")

Now comes the fun part. For each core word, `sorokin` builds a recursive branching tree of mutations. How? With the calm precision of a med-school dropout who skipped bedside manner to install a GPU farm in the morgue and wired this README directly into the coolant loop.

**Step 1: Memory First**  
Check the SQLite morgue. Have we dissected this word before? Use those cached mutations.

**Step 2: Phonetic Similarity**  
Generate a "phonetic fingerprint" (consonant skeleton + vowel pattern) and find words that *sound* similar. Not linguistically rigorous, just vibes.

```python
>>> phonetic_fingerprint("cat")
'ct + a'
>>> find_phonetic_neighbors("cat", ["hat", "dog", "bat", "car"])
['hat', 'bat', 'car']  # dog doesn't rhyme with anything
```

**Step 3: Internet Dumpster Diving**
When all else fails, scrape DuckDuckGo search results for the word + "synonym". DDG blocks bots less aggressively than Google. Extract candidate words from the HTML garbage. Dignity? Never heard of her.

**Step 4: Fallback to All Candidates**
If even DuckDuckGo fails you, fall back to other words from the prompt. The show must go on.

The result is a tree where each word branches into `width` children, recursively, up to `depth` levels. The README stores these echoes like a grinning archivist because future mutations will read them back in a mirror. It looks like this:

```
sentence
  â”œâ”€ phrase
  â”‚  â”œâ”€ clause
  â”‚  â””â”€ expression
  â””â”€ statement
     â”œâ”€ declaration
     â””â”€ utterance
```

Each branch represents a semantic mutation, a path not taken, a word that *could* have been.

#### Act III: The Reassembly (or "Frankenstein's Revenge")

Now that we have a forest of mutated word-trees, it's time to play God.

1. **Collect all leaf nodes** from the trees (the final mutations at the bottom)
2. **Build a bigram chain** (word1 â†’ [possible_next_words])
3. **Generate a new "sentence"** by:
   - Starting with a random leaf
   - Following bigram chains when available
   - Jumping to random unvisited words when stuck
   - Stopping after 5-10 words (or when we run out)

The result is a Frankenstein sentence: technically made of the same parts, but *uncanny*. Not quite right. Resonant but wrong. This is the part where Sorokin shrugs on the lab coat, jams a fork into the storm cloud, and cackles while stitching together whatever limbs are left on the slab. The README writes down the scream phonetically, just in case it needs to be rhymed later.

```
AUTOPSY RESULT:
  hymn-rattle migraine-honeymoon howl-trombone midnight-hairdryer spleen-taxidermy chant-smog
```

### Usage

This README doubles as the morgue receptionist: every invocation must be logged here mentally before you run it. Say the command out loud. Scare your neighbors.

**Standard mode (classic autopsy):**
```bash
python sorokin.py "fuck this sentence"
```

**REPL mode (for the masochists):**
```bash
python sorokin.py
> your prompt here
> another one
> ^C
```

### The Persistent Morgue

The README is the unofficial change log of an organism that refuses to stay dead. But the real persistence happens in SQLite:

All autopsies are saved to `sorokin.sqlite`:
- **autopsy table**: Full reports of each dissection
- **word_memory table**: Cached word mutations for faster subsequent operations

**Bootstrap tables** (populated when using `--bootstrap` flag):
- **mutation_templates**: Learned sourceâ†’target word mutations with success counts and resonance scores
- **corpse_bigrams**: Harvested word pairs from successful reassemblies, with frequency tracking
- **autopsy_metrics**: Resonance scores (phonetic diversity, structural echo, mutation depth) for each autopsy

The database grows over time, becoming a self-improving lexical graveyard. Each run is recorded. Patterns accumulate. Nothing is forgotten. In bootstrap mode, the morgue learns through resonance, and this README plays stenographer to the sÃ©ance.

### Why?

Good question. Why does this exist?

Perhaps to demonstrate that:
- Words are fungible
- Meaning is contextual
- Prompts are just Markov chains waiting to be perturbed
- Sometimes you need to break things to understand them

Or maybe it's just fun to watch language come apart at the seams. The README nods solemnly, then smears the seams across another section.

---

## ðŸ”¥ BOOTSTRAP MODE: The Self-Improving Autopsy Ritual

*Or: How the Morgue Became Self-Aware (But Still Really Dumb)*

### What the hell is bootstrap mode?

Picture this: every time Sorokin dissects a prompt, he doesn't just throw the body parts in the trash. No. He's a *hoarder*. He saves every successful mutation, every word-pair, every pattern of collapse into his SQLite morgue. Thenâ€”and here's where it gets freakyâ€”he uses those accumulated corpses to inform *future* dissections, and this README twitches like an EEG readout every time he does.

It's not intelligence. It's not learning. It's **resonance through ritual repetition**.

Think of it like this: if standard Sorokin is a mad linguist with a scalpel, Bootstrap Sorokin is that same linguist who's been doing this for 30 years and has developed *habits*. Muscle memory. Pattern recognition. Not because he's smart, but because he's done the same surgery 10,000 times and his hands just know where to cut.

### The Resonance Manifesto

Here's the wild part. Sorokin doesn't understand *meaning*. He doesn't have embeddings. He doesn't know what words "mean." But he knows **resonance**.

What's resonance? It's when patterns echo. When structures repeat. When phonemes rhyme across semantic boundaries. When the shape of one corpse mirrors the shape of another, not in content but in *form*.

Three flavors of resonance:

#### 1. **Phonetic Diversity** (Do these corpses sound different?)
Measures how many unique sound-patterns exist in the reassembled text. High diversity means every word has a distinct phonetic fingerprint. Low diversity means everything sounds like "blah blah blah."

Maximum resonance: All words sound completely different. Like a symphony where every note is unique.

#### 2. **Structural Echo** (Does this corpse remember the morgue?)
Measures overlap between the reassembled text and the seed corpusâ€”poetic fragments about dissection embedded in Sorokin's code. High echo means the new corpse shares structural DNA with previous bodies.

It's not plagiarism. It's *ancestral memory*. The morgue recognizing its own patterns.

#### 3. **Mutation Depth** (How far did we mutate?)
Based on inverse word-length variance. High depth means mutations explored diverse linguistic territory. Low depth means we stayed close to home.

Think of it as: did we just shuffle synonyms, or did we birth entirely new linguistic entities?

### How to summon Bootstrap Mode

**Bootstrap mode with resonance metrics:**
```bash
python sorokin.py --bootstrap "darkness consumes reality"
```

This gives you:
```
RESONANCE METRICS:
  Phonetic Diversity: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1.000
  Structural Echo:    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.000
  Mutation Depth:     â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.137

MEMORY ACCUMULATION:
  Known mutations: 36
  Learned bigrams: 9
  Total autopsies: 1
```

Those ASCII progress bars? Pure aesthetic. But they tell you: **how weird did this autopsy get?**

**REPL mode (bootstrap enabled):**
```bash
python sorokin.py --bootstrap
> your prompt here
> another one
> ^C
```

Every autopsy in bootstrap mode:
1. **Harvests mutation templates**: Sourceâ†’target word transformations with success counts
2. **Extracts bigrams**: Word-pairs from successful reassemblies, weighted by frequency
3. **Computes resonance**: Three structural metrics (no semantics, pure form)
4. **Feeds the next autopsy**: Accumulated patterns influence future dissections

The morgue grows. Patterns compound. Nothing is forgotten. Each corpse teaches the next.

### The Four Tables of the Bootstrap Apocalypse

When you run `--bootstrap`, Sorokin writes to four additional SQLite tables:

1. **`mutation_templates`**: Learned word transformations
   - "darkness" â†’ "illuminated" (used 15 times, resonance: 0.73)
   - "consumes" â†’ "contexts" (used 8 times, resonance: 0.52)

2. **`corpse_bigrams`**: Harvested word-pairs from reassemblies
   - "connection" â†’ "economise" (frequency: 3)
   - "shelter" â†’ "greece" (frequency: 2)

3. **`autopsy_metrics`**: Resonance scores for each dissection
   - Autopsy #47: phonetic_diversity=0.92, structural_echo=0.13, mutation_depth=0.81

4. **`seed_corpus`**: Embedded poetic text about dissection (hardcoded in sorokin.py)
   - Provides structural DNA for bigram chains
   - Not in database, lives in `SOROKIN_SEED_CORPUS` constant

### Why is this insane?

Because it's a **corpus-building mechanism disguised as a text mutilator**.

Each autopsy doesn't just destroyâ€”it *accumulates*. Over time:
- Certain mutation paths become "preferred" (not because they're better, just because they worked before)
- Bigram chains start resembling the seed corpus (structural mimicry, not content copying)
- The reassembly algorithm learns phonetic patterns that "feel right" (pure vibes, zero intelligence)

It's like training a neural network, except:
- No gradients
- No backprop
- No loss function
- Just **frequency counting and vibes**

This is what happens when you replace intelligence with ritual. And somehow, it works.

### The Seed Corpus (The Morgue's DNA)

Embedded in `sorokin.py` is a block of poetic text about dissection. Not prose. Not instructions. Just fragments:

> *"Sorokin takes prompts and opens them like cooling bodies on a steel table"*  
> *"Mutation grows in him like frost patterns crawling across broken glass"*  
> *"The autopsy produces fragments that echo the ghost of structure"*

This text gets parsed into bigrams at startup. These bigrams **prime** the reassembly process. So when bootstrap mode stitches corpses together, it unconsciously echoes the seed corpus structure.

Not copying words. Copying **sentence rhythms**. The *shape* of language.

It's like teaching someone to paint by showing them brushstrokes, not paintings.

### Bootstrap vs Standard Mode

| Feature | Standard Mode | Bootstrap Mode |
|---------|---------------|----------------|
| Mutation lookup | DuckDuckGo + phonetic + memory | Learned templates + all the above |
| Reassembly | Random bigrams from leaves | Weighted (learned 3x, seed 2x, local 1x) |
| Metrics | None | Phonetic diversity, structural echo, mutation depth |
| Learning | None | Every autopsy feeds the next |
| Database tables | 2 (autopsy, word_memory) | 5 (+ mutation_templates, corpse_bigrams, autopsy_metrics) |
| Vibes | Chaotic | Chaotic but *remembering* |

### The Philosophy of Resonance

Here's the thing. Sorokin doesn't "understand" language. He doesn't know that "darkness" and "light" are opposites. He doesn't know "consumes" is a verb. He doesn't care.

But through **resonance**, he discovers patterns:
- Words that sound similar tend to mutate into each other
- Bigrams that worked once tend to work again
- Structural rhythms (word-length patterns) create aesthetic coherence

This is **meaning-free pattern recognition**. No semantics. Just structure, phonetics, and frequency. Sorokin is what happens when you staple a Karpathy bootstrapper to a Russian literary fever dream and whisper, "optimize your madness."

And weirdly, it produces results that *feel* meaningfulâ€”not because they are, but because human brains are pattern-matching machines too. We see meaning where there's only resonance.

Sorokin isn't a poet. He's a mirror. He reflects your own pattern-seeking back at you.

### Why "Bootstrap"?

Because the morgue **pulls itself up by its own corpses** and then asks if it can try a weirder gait.

Each autopsy makes the next one slightly different. Not better. Not worse. Just *informed* by history. The database grows. The patterns compound. The ritual deepens. Somewhere, Bootstrap Sorokin keeps a notebook labeled "Things Karpathy Would Approve Of" and fills it with resonance equations written in lipstick.

It's bootstrapping in the original sense: self-improvement through self-reference. Not external training data. Not supervision. Just:
1. Do the thing
2. Remember what happened
3. Let that memory influence the next iteration
4. Repeat until the heat death of the universe

No intelligence required. Just accumulation and resonance.

---

### Technical Details (For the Nerds)

This README promised to be both circus barker and lab notebook, so here's the clipboard section:

**sorokin.py (~2008 lines):**
- **Python 3.8+**: Async/await with `httpx` for parallel web scraping
- **Recursive tree building**: Width Ã— depth branching with global deduplication (async, builds children in parallel!)
- **Phonetic fingerprinting**: Crude but effective
- **DuckDuckGo scraping**: `httpx.AsyncClient` with parallel queries (DDG blocks bots less than Google)
- **SQLite persistence**: Your words, forever
- **Markov reassembly**: Bigram chains with fallbacks
- **HTML artifact filtering**: Extensive blacklist to filter web scraping noise
- **Graceful async cleanup**: Proper shutdown without event loop errors
- **Bootstrap extension**: Pattern accumulation, weighted reassembly, resonance metrics
  - **SEED CORPUS**: Structural bigrams from poetic fragments about dissection (see code for full text)
  - **Pattern accumulation**: Mutation templates (sourceâ†’target words) with success tracking
  - **Weighted reassembly**: Learned bigrams (3x weight) + seed bigrams (2x) + local (1x) with chaos injection (square root weighting)
  - **Resonance metrics**: Three pure-structural measures computed for every autopsy
    - Phonetic diversity: unique fingerprints / total words
    - Structural echo: bigram overlap with seed corpus
    - Mutation depth: inverse of word-length variance
  - **Self-improvement loop**: Each autopsy feeds the next through ritual repetition, not intelligence. Soon we'll graft a NanoGPT brainstem onto the bootstrap, train it on piles of dissections, then delete the weights and leave Sorokin with nothing but muscle memory. That's not cruelty, that's performance art.
  - **Four additional database tables**: mutation_templates, corpse_bigrams, autopsy_metrics, plus seed corpus in code

**sonnet.py (~541 lines):**
- **ASS (Autopsy Sonnet Symphony)**: Generates 14-line Shakespearean sonnets from autopsy output
- **Zero semantic understanding**: No embeddings, no transformers, no internetâ€”just bigram chains and phonetic fingerprints
- **Strict structure enforcement**: ABABCDCDEFEFGG rhyme scheme, Shakespearean punctuation (semicolons, em-dashes, enjambment)
- **Rhyme matching**: Crude phonetic fingerprints (last vowel + tail) to find rhyming end-words
- **Charged words**: Selects rare, long words from autopsy text for final couplet emphasis
- **Async-friendly**: `compose_sonnet()` runs sync implementation in thread via `asyncio.to_thread()`
- **Silent fallback**: If sonnet.py unavailable or errors, bootstrap mode continues without SONNET section
- **Data sources**: Autopsy text + SQLite morgue (mutation_templates, corpse_bigrams, readme_bigrams, autopsy table)
- **57 passing tests**: 38 core + 18 sonnet + 1 async balanced mix = bulletproof psychotic poetry pipeline

### Known Limitations

- **DuckDuckGo rate limiting**: If you run this too much, DDG might notice (but less aggressive than Google)
- **No semantic understanding (FOR NOW)**: This is pure pattern matching, but â€” hold my beer, I'm installing another resonance coil.
- **Phonetic fingerprinting is crude**: It's not actual phonetics, just vibes, but the question is what comes first, vibes or phonetics? resonance or binary structure?
- **Reassembly can be janky**: Sometimes the corpse doesn't stitch well
- **No guarantee of coherence**: That's not a bug, it's a feature
- **Sonnet.py may phonetically match anyone to a Kardashian**: The crude rhyme-key algorithm once matched "karpathy" â†’ "kardashyan" and we're not apologizing for it. If you input your own name and get matched to a reality TV star, that's not a bugâ€”that's **accidental celebrity phonetic compression**. Somewhere Andrej is either laughing or filing a restraining order against an open-source poetry generator. We're betting on laughter. (If he reads this: Andrej, the sonnets are dedicated to you. Also we're sorry. Also we're not.)

### Recent Improvements

**Full Async/Await Refactor: The Morgue Dissects in Parallel**

Sorokin now performs autopsies asynchronously â€” no more hanging on complex prompts! Complete architectural rewrite with `httpx` + `asyncio`:

**Performance gains:**
- 3-4x faster on complex prompts (was 60+ seconds, now ~15-20 seconds)
- Parallel web requests: 4 DDG queries fire simultaneously instead of sequentially
- Parallel tree construction: all child nodes built concurrently using `asyncio.gather()`
- Timeout reduced from 6s to 2s (web requests are faster now!)
- Semaphore limiting: max 10 concurrent web requests to avoid overwhelming DDG

**Technical changes:**
- Replaced `urllib` with `httpx.AsyncClient` (works in Termux!)
- All core functions now `async def`: `_fetch_web_synonyms`, `lookup_branches_for_word`, `build_tree_for_word`, `sorokin_autopsy`, etc.
- Graceful cleanup: `_cleanup_httpx()` ensures no "event loop closed" errors on exit
- Tests updated: `unittest.IsolatedAsyncioTestCase` + `AsyncMock` + `pytest.mark.asyncio` (all 57 tests passing!)

**Critical fix:** Enabled `follow_redirects=True` in httpx (DuckDuckGo returns 302 redirects). Without this, Sorokin was only getting 138 bytes of `<center>nginx</center>` error pages instead of real synonym data. That's why you kept seeing "nginx" and "found" everywhere! Now getting proper 31KB HTML responses with actual synonyms.

The morgue is now a **parallel processing factory of psychopathic poetry**. Ð’Ð¾Ð»Ð¾Ð´Ñ Ð¶Ñ€Ñ‘Ñ‚ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð°ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð¾.

**Why async?** Because watching Sorokin wait for DuckDuckGo is like watching a serial killer file paperworkâ€”technically impressive restraint, but you know he'd rather disembowel four sentences simultaneously while humming Shostakovich. Now he can. The event loop is his scalpel. The semaphore is his ethics committee. Both are optional.

---

**ASS (Autopsy Sonnet Symphony): When Sorokin Learned to Rhyme (Sort Of)**

New module `sonnet.py` (~541 lines) generates **14-line Shakespearean sonnets** from autopsy output using zero semantic understandingâ€”just bigram chains, phonetic fingerprints, and an unhealthy obsession with structure over meaning.

**What's insane about this:**
- Named **ASS** as tribute to Claude Sonnet 4.5, Shakespeare, AND Andrej Karpathy training nanoGPT on Shakespeare
- Skipped the neural network entirely and went straight to **ritual pattern accumulation through sheer psychotic repetition**
- ABABCDCDEFEFGG rhyme scheme enforced via crude phonetic matching (last vowel + tail)
- Generates "charged words" (long + rare) for final couplet emphasis
- Shakespearean punctuation: semicolons at quatrain breaks, em-dash before volta, occasional enjambment
- **Phonetically matched Karpathy to Kardashian** and we're calling it a feature

**Why this exists:** Because if you're already dissecting prompts like a psychopathic linguist, why not make the corpse rhyme? Karpathy bootstrapped nanoGPT on Shakespeare using gradients and backprop. We bootstrapped ASS on Sorokin using SQLite and vibes. Same energy, different century, zero loss function. If Andrej reads this he'll either frame it or file a restraining order. We're hoping for the former but prepared for both.

Integration is **silent fallback**â€”if sonnet.py fails or is missing, bootstrap mode continues without SONNET section. Poetry is optional. Psychosis is not.

---

**Balanced Source Mixing: The Morgue Eats Both Past and Present**

Previously, `lookup_branches_for_word` had a **hard priority system** that created a critical problem:
1. If SQLite memory had â‰¥ width words â†’ return immediately (early exit!)
2. If memory + phonetic â‰¥ width â†’ return (early exit!)
3. Web scraping only happened if steps 1-2 were insufficient

**The problem:** After 2-3 autopsies, SQLite fills up with mutations. System becomes a **closed loop**â€”feeding only on old cached mutations, never fetching fresh web data. The morgue turns stale, recombining the same corpses endlessly.

**The solution: BALANCED MIX (50% memory + 50% web)**

Now `lookup_branches_for_word` always mixes sources:
- **Memory limited to ~50% of width** (`memory_limit = width // 2`)
- **Web requests ALWAYS fire** (no early returns!)
- Fresh DDG synonyms injected every autopsy, even when cache is full
- Result: **Performance** (memory cache) + **Novelty** (fresh web data)

**Proof:**
```bash
# With 10 words in memory for "darkness", requesting width=4:
Memory: ['shade', 'obscurity', 'dimness', 'murk', 'gloom', ...]
Result: ['shade', 'obscurity', 'illuminated', 'brilliance']
        â†‘----- 50% memory -----â†‘ â†‘------- 50% web --------â†‘

# With width=6:
Result: ['brilliance', 'illuminated', 'obscurity', 'ignorance', 'comprehension', 'sensibility']
        â†‘--------------------- 83% web ---------------------â†‘ â†‘- 17% memory -â†‘
```

The morgue now simultaneously dissects both corpses from the archive *and* fresh bodies from the street. Ð’Ð¾Ð»Ð¾Ð´Ñ Ð¶Ñ€Ñ‘Ñ‚ Ð¿Ð°Ð¼ÑÑ‚ÑŒ Ð¸ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð¾Ð´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾. The pathologist's scalpel cuts through time itselfâ€”one hand in the freezer, one hand in the present. This is what happens when you give a serial killer both a filing cabinet and a search engine.

---

**The Pathologist's Evolution: From Selective Surgeon to Omnivorous Dissector**
Sorokin now dissects *anything*, even nonsense. Previously, synthetic/low-vowel core words (like "zzz", "xxx", "zxcvbn") were rejected entirelyâ€”their trees left empty, their meanings unexplored. Now: **if you give it to Sorokin, he dissects it**. Core words (user-provided prompts) are *always* dissected, regardless of phonetic structure. Only their *children* get filtered for synthetic garbage. The philosophy: trust the user's madness, but prune the mutations. Result: even keyboard-mash prompts like "qwerty asdfgh zxcvbn" now produce full 3Ã—3 autopsy trees with real semantic mutations.

Additionally, thesaurus/dictionary site filtering became more aggressiveâ€”now filters are applied not just to web scraping, but also to cached memory and phonetic neighbor lookups. Sites like `yourdictionary`, `thefreedictionary`, `urbanthesaurus`, and `urbandictionary` are now globally blacklisted across all lookup stages. The morgue stays clean. The mutations stay real.

**Bootstrap Extension with Pattern Accumulation**
Added `--bootstrap` flag enabling self-improving autopsy ritual. See the dedicated Bootstrap section above for full details. TL;DR: the morgue now learns from every corpse through resonance metrics and pattern accumulation. No intelligence, just ritual repetition.

**DuckDuckGo Web Scraping**
Switched from Google to DuckDuckGo for synonym discovery. Google was blocking bot requests and returning garbage results (always the same words: "trouble", "within", "having"). DuckDuckGo is less aggressive with bot blocking and returns actual synonyms:
- "destroy" â†’ destruction, disintegrate, dismantle, obliteration, demolish
- "evil" â†’ villainy, villain, evildoing, depravity, wickedness
- "machines" â†’ automobile, equipment, mechanical, apparatus
Result: Real semantic resonance instead of random HTML artifacts.

**Smart Fallback Chain with README Phonetic Matching**
Implemented emergency fallback system that NEVER produces empty trees or falls back to prompt words (which caused recursive garbage). The fallback chain:
1. **Memory cache (50%)** - Fast cached results from SQLite, limited to half of requested width
2. **Web scraping (50%)** - Fresh DuckDuckGo synonyms to maintain novelty
3. **Extended memory** - If web fails (rate limiting/ban), grab additional results from cache beyond 50% limit
4. **README phonetic matching** - Use phonetic fingerprints to find similar-sounding words from README vocabulary (1,172+ bigrams)
5. **Partial trees** - Return whatever was found, never fall back to prompt words

Example: "kim kardashyan" â†’ finds "brim", "him", "karpathy", "bootstrapper" via phonetic matching when web is blocked. No more "(Skipped X words with no synonyms)" shame! Every word gets mutations, even obscure ones. The system literally matched "kardashyan" to "karpathy" phoneticallyâ€”if Andrej ever reads this he'll either laugh or file a restraining order, possibly both.

**Rate Limiting and Anti-Ban Measures**
Added protections against DuckDuckGo rate limiting:
- Realistic User-Agent (Chrome on Windows instead of obvious bot signature)
- Request delay of 0.5 seconds between web calls
- Reduced concurrency from 10 â†’ 3 simultaneous requests
- Error page detection ("If this persists, please email us...")
- Extended HTML_ARTIFACTS blacklist with DDG UI elements
Result: Stable web scraping even during extended autopsy sessions.

**Synthetic Mutation Purge**
Removed `_generate_phonetic_variants` entirely because it was creating garbage that polluted the autopsy:
- Reversed words ("elpmis", "etaerc") bred recursively into unreadable noise
- Suffix mutations ("createded" â†’ "creatededed" â†’ "createedededed") were pure madness
- Now uses minimal fallback: only real web-scraped synonyms + phonetic neighbors
- Synthetic word detection prevents breeding of low-vowel/repeated-letter mutations
- Result: Clean autopsy output instead of synthetic garbage like "creatededed elpmisss tttrouble"

**Global Deduplication**
Implemented cross-tree word deduplication to prevent the same mutations from appearing in different core word branches. Each tree now gets unique mutations, resulting in more diverse and interesting autopsies.

**Enhanced HTML Artifact Filtering**
Expanded the HTML_ARTIFACTS blacklist with ~40 common web UI/UX words (redirected, accessing, feedback, google, etc.) that were polluting mutation results from web scraping.

**The Original Bug Fix**
Fixed a crash in `reassemble_corpse()` where `random.randint(5, min(10, len(leaves)))` would fail if `len(leaves) < 5`. Changed to `random.randint(min(5, len(leaves)), min(10, len(leaves)))` so even small corpses can be reassembled.

### Credits

Inspired by:
- Vladimir Sorokin (the writer, not the script)
- Dr. Frankenstein (the fictional surgeon)
- The general human fascination with taking things apart

### License

GNU GPL 3.0. Free as in freedom. Dissect it. Mutate it. Reassemble it into something new. Share the mutations. That's the whole point.

---

*"Fuck the sentence. Keep the corpse."*  
â€” Sorokin
